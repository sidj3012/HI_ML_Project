README

Overview
This project explores whether incorporating audio files, detecting emotions, and using those emotions in translation can improve the quality of translations. We are specifically evaluating English-to-French translation using three different large language model (LLM) pipelines: Qwen, Mistral, and Phi. The effectiveness of this approach is assessed by comparing the translations using BLEU and COMET scores.
The project uses audio files in addition to textual data to experiment with emotion detection, which may influence the translation results. We are testing if integrating this emotional context improves the translation output.

Files

1. Translation Pipelines
- **qwen_pipeline.ipynb**  
  Implements the Qwen LLM pipeline for general tasks, including translation.

- **mistral_pipeline.ipynb**  
  Implements the Mistral LLM pipeline specifically designed for English-to-French translation.

- **phi_pipeline.ipynb**  
  Implements the Phi LLM pipeline for translation and other language modeling tasks.

2. Datasets
- **`english.csv`**  
  Contains English text to be translated.

- **`french.csv`**  
  Contains the gold standard French translations of the English text in `english.csv`.

- **`qwen_translations.csv`**  
  Contains the French translations generated by the Qwen pipeline for the text in `english.csv`.

- **`mistral_translations.csv`**  
  Contains the French translations generated by the Mistral pipeline for the text in `english.csv`.

- **`phi_translations.csv`**  
  Contains the French translations generated by the Phi pipeline for the text in `english.csv`.

3. Audio Files and Speech Emotion Recognition
- **`data_files/`**  
  Contains audio files associated with the English text, used for emotion detection in the translation process.

  - **`data.en/`**  
    Contains English audio files corresponding to the text in `english.csv`.

  - **`data.fr/`**  
    Contains French audio files corresponding to the gold standard translations in `french.csv`.

  - **`alignments.meta`**  
    Contains metadata that aligns English text with French translations and audio files, which aids in the emotion detection and contextual alignment.

- Run **`wav_to_array_conversion.ipynb`** on local machine to generate **`audio_array_data.json`**
- Run **`ser_implemented.ipynb`** on Google Colab to generate **`ser_output.csv`**, Note: upload **`audio_array_data.json`** in run time environment

4. Evaluation
- **`evaluations.ipynb`**  
  Computes evaluation metrics (COMET and BLEU scores) by comparing `french.csv` (gold standard) with the translation outputs:
  - `qwen_translations.csv`
  - `mistral_translations.csv`
  - `phi_translations.csv`

  This notebook also evaluates if incorporating emotional context from the audio files improves the translation performance.

Usage

1. Run Translation Pipelines
   - Open the respective pipeline notebook (`qwen_pipeline.ipynb`, `mistral_pipeline.ipynb`, or `phi_pipeline.ipynb`).
   - Execute the cells to translate `english.csv` into French using the desired model.

2. Process Audio Files for Emotion Detection  
   - The audio files in `data.en/` and `data.fr/` will be used in the pipelines for emotion detection.
   - The `alignments.meta` file will help align the English text with the corresponding French translation and audio.

3. Generate Translations
   - After running each pipeline, the outputs will be saved in their respective files (`qwen_translations.csv`, `mistral_translations.csv`, and `phi_translations.csv`).

4. Evaluate Translations  
   - Open `evaluations.ipynb`.
   - Run the notebook to compute BLEU and COMET scores, which compare the translation outputs against the gold standard in `french.csv`.

Requirements
- Python 3.x
- Jupyter Notebook
- Required libraries for each LLM (as specified in their respective notebooks)
- Evaluation libraries (e.g., `sacrebleu`, `comet-ml`)
